{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2c1c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('./bc_data.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2e9913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.linspace(0.05, 0.5, 10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d011c904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [2, 1],\n",
       "       [2, 1],\n",
       "       [2, 1],\n",
       "       [2, 1],\n",
       "       [2, 1],\n",
       "       [2, 1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load('./actions.npz')\n",
    "a['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Box, MultiDiscrete\n",
    "import numpy as np\n",
    "import heapq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from flask import Flask, request\n",
    "import threading\n",
    "import time\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.buffers import DictRolloutBuffer\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import MultiInputActorCriticPolicy\n",
    "import cv2\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Rule-based model (example)\n",
    "def rule_based_model(obs):\n",
    "    # Example rule-based action generation\n",
    "    # Input: obs = {\"image\": [128, 128, 2], \"sensors\": [9]}\n",
    "    # Output: action = {\"main\": [action_idx, weight_idx], \"extra\": [5,]}\n",
    "    image = obs[\"image\"]  # [128, 128, 2]\n",
    "    sensors = obs[\"sensors\"]  # [9]\n",
    "    # Simple rule: choose action based on sensor values\n",
    "    action_idx = int(np.clip(sensors[0] * 4, 0, 3))  # Example: sensor[0] scaling\n",
    "    weight_idx = int(np.clip(sensors[1] * 10, 0, 9))  # Example: sensor[1] scaling\n",
    "    extra_data = sensors[:5]  # Example: first 5 sensor values\n",
    "    return {\n",
    "        \"main\": np.array([action_idx, weight_idx], dtype=np.int64),\n",
    "        \"extra\": extra_data.astype(np.float32)\n",
    "    }\n",
    "\n",
    "# Behavior Cloning pretraining\n",
    "def behavior_cloning_pretrain(model, bc_dataset, epochs=5, batch_size=64, lr=3e-4):\n",
    "    optimizer = torch.optim.Adam(model.policy.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        np.random.shuffle(bc_dataset)\n",
    "        total_loss = 0\n",
    "        for i in range(0, len(bc_dataset), batch_size):\n",
    "            batch = bc_dataset[i:i + batch_size]\n",
    "            obs_batch = {\n",
    "                \"image\": torch.tensor(np.stack([d[\"obs\"][\"image\"] for d in batch]), dtype=torch.float32).to(device),\n",
    "                \"sensors\": torch.tensor(np.stack([d[\"obs\"][\"sensors\"] for d in batch]), dtype=torch.float32).to(device)\n",
    "            }\n",
    "            action_batch = {\n",
    "                \"main\": torch.tensor(np.stack([d[\"action\"][\"main\"] for d in batch]), dtype=torch.int64).to(device),\n",
    "                \"extra\": torch.tensor(np.stack([d[\"action\"][\"extra\"] for d in batch]), dtype=torch.float32).to(device)\n",
    "            }\n",
    "            # Forward pass\n",
    "            with torch.no_grad():\n",
    "                _, log_prob, _ = model.policy(obs_batch, action=action_batch)\n",
    "            # Loss: maximize log probability for main, minimize MSE for extra\n",
    "            main_loss = -log_prob.mean()  # Negative log probability for MultiDiscrete\n",
    "            extra_loss = F.mse_loss(model.policy.forward(obs_batch)[0][\"extra\"], action_batch[\"extra\"])\n",
    "            loss = main_loss + extra_loss\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.policy.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"BC Epoch {epoch+1}/{epochs}, Loss: {total_loss / (len(bc_dataset) // batch_size)}\")\n",
    "    return model\n",
    "\n",
    "# Collect BC dataset\n",
    "def collect_bc_dataset(env, rule_model, num_samples=1000):\n",
    "    dataset = []\n",
    "    obs, _ = env.reset()\n",
    "    for _ in range(num_samples):\n",
    "        action = rule_model(obs)\n",
    "        dataset.append({\"obs\": obs, \"action\": action})\n",
    "        new_obs, reward, done, info = env.step(action)\n",
    "        obs = new_obs\n",
    "        if done:\n",
    "            obs, _ = env.reset()\n",
    "    return dataset\n",
    "\n",
    "# Custom DummyVecEnv\n",
    "class CustomDummyVecEnv(DummyVecEnv):\n",
    "    def __init__(self, env_fns):\n",
    "        super().__init__(env_fns)\n",
    "        self.step_results = []\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.buf_obs = {\n",
    "            key: np.zeros((self.num_envs,) + self.observation_space[key].shape, dtype=self.observation_space[key].dtype)\n",
    "            for key in self.observation_space.spaces.keys()\n",
    "        }\n",
    "        infos = []\n",
    "        for env_idx, env in enumerate(self.envs):\n",
    "            obs, info = env.reset(seed=seed, options=options)\n",
    "            for key in self.buf_obs:\n",
    "                self.buf_obs[key][env_idx] = obs[key]\n",
    "            infos.append(info)\n",
    "        print(f\"Reset buf_obs: image={self.buf_obs['image'].shape}, sensors={self.buf_obs['sensors'].shape}, image_nonzero={np.any(self.buf_obs['image'])}\")\n",
    "        return self.buf_obs, infos[0] if infos else {}\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.step_results = []\n",
    "        for env_idx, env in enumerate(self.envs):\n",
    "            result = env.step(actions[env_idx])\n",
    "            self.step_results.append(result)\n",
    "\n",
    "    def step_wait(self):\n",
    "        self.buf_obs = {\n",
    "            key: np.zeros((self.num_envs,) + self.observation_space[key].shape, dtype=self.observation_space[key].dtype)\n",
    "            for key in self.observation_space.spaces.keys()\n",
    "        }\n",
    "        rewards, dones, infos = [], [], []\n",
    "        for i, (obs, rew, terminated, truncated, info) in enumerate(self.step_results):\n",
    "            done = terminated or truncated\n",
    "            for key in self.buf_obs:\n",
    "                self.buf_obs[key][i] = obs[key]\n",
    "            rewards.append(rew)\n",
    "            dones.append(done)\n",
    "            infos.append(info)\n",
    "        print(f\"Step buf_obs: image={self.buf_obs['image'].shape}, sensors={self.buf_obs['sensors'].shape}, image_nonzero={np.any(self.buf_obs['image'])}\")\n",
    "        return self.buf_obs, np.array(rewards), np.array(dones), infos\n",
    "\n",
    "# Flask app\n",
    "app = Flask(__name__)\n",
    "data_heap = []\n",
    "heap_lock = threading.Lock()\n",
    "current_action = None\n",
    "action_lock = threading.Lock()\n",
    "current_obs = None\n",
    "obs_lock = threading.Lock()\n",
    "rollout_buffer = None\n",
    "model = None\n",
    "env = None\n",
    "step_counter = 0\n",
    "total_steps = 100000\n",
    "n_steps = 2048\n",
    "is_first_request = True\n",
    "\n",
    "# Simulator request handling\n",
    "@app.route('/simulator_data', methods=['POST'])\n",
    "def receive_data():\n",
    "    global step_counter, current_action, current_obs, is_first_request\n",
    "    data = request.json\n",
    "    timestamp = time.time()\n",
    "    with heap_lock:\n",
    "        heapq.heappush(data_heap, (-timestamp, data))\n",
    "        print(f\"Data received at: {timestamp}, Heap size: {len(data_heap)}, Image shape: {np.array(data['image']).shape}\")\n",
    "    \n",
    "    if model is None or env is None:\n",
    "        return {\"status\": \"Model not initialized\"}, 200\n",
    "    \n",
    "    with heap_lock:\n",
    "        if not data_heap:\n",
    "            return {\"status\": \"No data\"}, 200\n",
    "        _, latest_data = heapq.heappop(data_heap)\n",
    "    \n",
    "    if is_first_request:\n",
    "        # First request: Action prediction\n",
    "        obs = {\n",
    "            \"image\": np.array(latest_data[\"image\"], dtype=np.uint8),  # [128, 128, 2]\n",
    "            \"sensors\": np.array(latest_data[\"sensors\"], dtype=np.float32)  # [9]\n",
    "        }\n",
    "        # Convert to torch.Tensor with batch dimension\n",
    "        obs_tensor = {\n",
    "            \"image\": torch.tensor(obs[\"image\"], dtype=torch.float32).unsqueeze(0).to(device),  # [1, 128, 128, 2]\n",
    "            \"sensors\": torch.tensor(obs[\"sensors\"], dtype=torch.float32).unsqueeze(0).to(device)  # [1, 9]\n",
    "        }\n",
    "        with obs_lock:\n",
    "            global current_obs\n",
    "            current_obs = obs\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action, value, log_prob = model.policy(obs_tensor, deterministic=False)\n",
    "        \n",
    "        with action_lock:\n",
    "            main_action = action[\"main\"]\n",
    "            action_idx, weight_idx = main_action\n",
    "            weight = model.env.envs[0].weight_bins[weight_idx]\n",
    "            current_action = {\"action\": int(action_idx), \"weight\": float(weight), \"extra\": action[\"extra\"]}\n",
    "        \n",
    "        is_first_request = False\n",
    "        return {\"status\": \"Action predicted\"}, 200\n",
    "    else:\n",
    "        # Second request: env.step()\n",
    "        with obs_lock:\n",
    "            obs = current_obs\n",
    "        \n",
    "        # Convert to torch.Tensor\n",
    "        obs_tensor = {\n",
    "            \"image\": torch.tensor(obs[\"image\"], dtype=torch.float32).unsqueeze(0).to(device),\n",
    "            \"sensors\": torch.tensor(obs[\"sensors\"], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action, value, log_prob = model.policy(obs_tensor, deterministic=False)\n",
    "        \n",
    "        # env.step() call with Dict action\n",
    "        new_obs, reward, done, info = env.step(action)\n",
    "        print(f\"Env output: image={new_obs['image'].shape}, sensors={new_obs['sensors'].shape}, done={done}\")\n",
    "        \n",
    "        # RolloutBuffer storage\n",
    "        obs_np = {\n",
    "            \"image\": obs_tensor[\"image\"].cpu().numpy()[0],\n",
    "            \"sensors\": obs_tensor[\"sensors\"].cpu().numpy()[0]\n",
    "        }\n",
    "        action_np = {\n",
    "            \"main\": action[\"main\"].cpu().numpy() if isinstance(action[\"main\"], torch.Tensor) else action[\"main\"],\n",
    "            \"extra\": action[\"extra\"].cpu().numpy() if isinstance(action[\"extra\"], torch.Tensor) else action[\"extra\"]\n",
    "        }\n",
    "        rollout_buffer.add(\n",
    "            obs=obs_np,\n",
    "            actions=action_np,\n",
    "            rewards=np.array([reward]),\n",
    "            dones=np.array([done]),\n",
    "            values=value.cpu(),\n",
    "            log_probs=log_prob.cpu(),\n",
    "            episode_starts=np.array([False])\n",
    "        )\n",
    "        step_counter += 1\n",
    "        \n",
    "        # Policy update\n",
    "        if step_counter % n_steps == 0:\n",
    "            new_obs_tensor = {\n",
    "                \"image\": torch.tensor(new_obs[\"image\"], dtype=torch.float32).unsqueeze(0).to(device),\n",
    "                \"sensors\": torch.tensor(new_obs[\"sensors\"], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                next_value = model.policy.predict_values(new_obs_tensor)\n",
    "            rollout_buffer.compute_returns_and_advantage(last_values=next_value.cpu(), dones=np.array([done]))\n",
    "            model.train()\n",
    "            rollout_buffer.reset()\n",
    "        \n",
    "        # Learning complete\n",
    "        if step_counter >= total_steps:\n",
    "            model.save(\"ppo_custom_model\")\n",
    "            print(\"Learning completed\")\n",
    "            return {\"status\": \"Learning completed\"}, 200\n",
    "        \n",
    "        # Episode reset\n",
    "        if done:\n",
    "            obs, _ = env.reset(options={\n",
    "                \"image\": new_obs[\"image\"][0],\n",
    "                \"sensor_data\": new_obs[\"sensors\"][0].tolist()\n",
    "            })\n",
    "            with obs_lock:\n",
    "                current_obs = obs\n",
    "            is_first_request = True\n",
    "        else:\n",
    "            is_first_request = True\n",
    "        \n",
    "        return {\"status\": \"Step processed\"}, 200\n",
    "\n",
    "# Custom environment\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self, simulator_url=\"http://localhost:5000\", total_steps=100000):\n",
    "        super().__init__()\n",
    "        self.observation_space = Dict({\n",
    "            \"image\": Box(low=0, high=255, shape=(128, 128, 2), dtype=np.uint8),\n",
    "            \"sensors\": Box(low=-np.inf, high=np.inf, shape=(9,), dtype=np.float32)\n",
    "        })\n",
    "        self.action_space = Dict({\n",
    "            \"main\": MultiDiscrete([4, 10]),\n",
    "            \"extra\": Box(low=-np.inf, high=np.inf, shape=(5,), dtype=np.float32)\n",
    "        })\n",
    "        self.simulator_url = simulator_url\n",
    "        self.max_steps = 1000\n",
    "        self.step_count = 0\n",
    "        self.total_steps = total_steps\n",
    "        self.weight_bins = np.linspace(0.0, 0.9, 10)\n",
    "        self.render_mode = None\n",
    "        self.extra_param = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.step_count = 0\n",
    "        if options:\n",
    "            image = np.array(options[\"image\"], dtype=np.uint8)\n",
    "            sensors = np.array(options[\"sensor_data\"], dtype=np.float32)\n",
    "            print(f\"Reset with options: image={image.shape}, sensors={sensors.shape}\")\n",
    "            return {\"image\": image, \"sensors\": sensors}, {}\n",
    "        with heap_lock:\n",
    "            heapq.heapify(data_heap)\n",
    "            if data_heap:\n",
    "                _, data = heapq.heappop(data_heap)\n",
    "            else:\n",
    "                for _ in range(4):\n",
    "                    time.sleep(0.25)\n",
    "                    with heap_lock:\n",
    "                        if data_heap:\n",
    "                            _, data = heapq.heappop(data_heap)\n",
    "                            break\n",
    "                else:\n",
    "                    raise TimeoutError(\"No initial data from simulator\")\n",
    "        image = np.array(data[\"image\"], dtype=np.uint8)\n",
    "        sensors = np.array(data[\"sensors\"], dtype=np.float32)\n",
    "        print(f\"Reset with heap: image={image.shape}, sensors={sensors.shape}\")\n",
    "        return {\"image\": image, \"sensors\": sensors}, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        global current_action\n",
    "        start_time = time.time()\n",
    "        main_action = action[\"main\"]\n",
    "        extra_data = action[\"extra\"]\n",
    "        print(f\"Step action: main={main_action}, extra={extra_data}\")\n",
    "        if self.extra_param:\n",
    "            print(f\"Using extra param: {self.extra_param}\")\n",
    "        for _ in range(2):\n",
    "            with heap_lock:\n",
    "                if data_heap:\n",
    "                    _, data = heapq.heappop(data_heap)\n",
    "                    print(f\"Step data at: {data['timestamp']}\")\n",
    "                    break\n",
    "            time.sleep(0.25)\n",
    "        else:\n",
    "            raise TimeoutError(\"No result data from simulator\")\n",
    "        \n",
    "        image = np.array(data[\"image\"], dtype=np.uint8)\n",
    "        sensors = np.array(data[\"sensors\"], dtype=np.float32)\n",
    "        reward = float(data[\"reward\"])\n",
    "        self.step_count += 1\n",
    "        terminated = self.step_count >= self.max_steps or data.get(\"terminated\", False)\n",
    "        truncated = False\n",
    "        info = {\"step_time\": time.time() - start_time}\n",
    "        return {\"image\": image, \"sensors\": sensors}, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"human\":\n",
    "            image = self.observation_space[\"image\"].sample()\n",
    "            cv2.imshow(\"Environment\", image[:, :, 0])\n",
    "            cv2.waitKey(1)\n",
    "        return image\n",
    "\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Custom feature extractor\n",
    "class CustomFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            sample_image = torch.zeros(1, 2, 128, 128).to(device)\n",
    "            n_flatten = self.cnn(sample_image).shape[1]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(9, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(n_flatten + 64, features_dim),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, observations):\n",
    "        image = observations[\"image\"].permute(0, 3, 1, 2).float() / 255.0\n",
    "        print(f\"Forward input: image={image.shape}, sensors={observations['sensors'].shape}\")\n",
    "        image_features = self.cnn(image)\n",
    "        sensor_features = self.mlp(observations[\"sensors\"])\n",
    "        combined = torch.cat([image_features, sensor_features], dim=1)\n",
    "        return self.linear(combined)\n",
    "\n",
    "# PPO initialization with BC pretraining\n",
    "def initialize_ppo():\n",
    "    global model, env, rollout_buffer\n",
    "    env = CustomEnv(total_steps=total_steps)\n",
    "    env = CustomDummyVecEnv([lambda: env])\n",
    "    rollout_buffer = DictRolloutBuffer(\n",
    "        buffer_size=n_steps,\n",
    "        observation_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        device=device,\n",
    "        gae_lambda=0.95,\n",
    "        gamma=0.99,\n",
    "        n_envs=1,\n",
    "    )\n",
    "    model = PPO(\n",
    "        policy=MultiInputActorCriticPolicy,\n",
    "        env=env,\n",
    "        policy_kwargs={\"features_extractor_class\": CustomFeaturesExtractor},\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=n_steps,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        ent_coef=0.01,  # Encourage exploration post-BC\n",
    "        verbose=1,\n",
    "        device=device,\n",
    "    )\n",
    "    # Behavior Cloning pretraining\n",
    "    bc_dataset = collect_bc_dataset(env, rule_based_model, num_samples=1000)\n",
    "    model = behavior_cloning_pretrain(model, bc_dataset, epochs=5, batch_size=64, lr=3e-4)\n",
    "    return model, env, rollout_buffer\n",
    "\n",
    "# Flask server start\n",
    "if __name__ == \"__main__\":\n",
    "    model, env, rollout_buffer = initialize_ppo()\n",
    "    app.run(host=\"0.0.0.0\", port=5000, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d52678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.184069\n",
    "b = a // 0.05\n",
    "\n",
    "round(b * 0.05,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
