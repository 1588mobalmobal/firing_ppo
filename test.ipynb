{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict, Box, MultiDiscrete\n",
    "import numpy as np\n",
    "import heapq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flask import Flask, request\n",
    "import threading\n",
    "import time\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.buffers import DictRolloutBuffer\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import MultiInputActorCriticPolicy\n",
    "import cv2\n",
    "\n",
    "# 커스텀 DummyVecEnv\n",
    "class CustomDummyVecEnv(DummyVecEnv):\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.buf_obs = {key: [] for key in self.observation_space.spaces.keys()}\n",
    "        for env_idx, env in enumerate(self.envs):\n",
    "            obs, info = env.reset(seed=seed, options=options)\n",
    "            for key in self.buf_obs:\n",
    "                self.buf_obs[key].append(obs[key])\n",
    "        return {key: np.array(val, dtype=self.observation_space[key].dtype) for key, val in self.buf_obs.items()}, info\n",
    "\n",
    "# Flask 앱\n",
    "app = Flask(__name__)\n",
    "data_heap = []\n",
    "heap_lock = threading.Lock()\n",
    "current_action = None\n",
    "action_lock = threading.Lock()\n",
    "current_obs = None\n",
    "obs_lock = threading.Lock()\n",
    "rollout_buffer = None\n",
    "model = None\n",
    "env = None\n",
    "step_counter = 0\n",
    "total_steps = 100000\n",
    "n_steps = 2048\n",
    "is_first_request = True\n",
    "\n",
    "# 시뮬레이터 요청 처리\n",
    "@app.route('/simulator_data', methods=['POST'])\n",
    "def receive_data():\n",
    "    global step_counter, current_action, current_obs, is_first_request\n",
    "    data = request.json\n",
    "    timestamp = time.time()\n",
    "    with heap_lock:\n",
    "        heapq.heappush(data_heap, (-timestamp, data))\n",
    "        print(f\"Data received at: {timestamp}, Heap size: {len(data_heap)}\")\n",
    "    \n",
    "    if model is None or env is None:\n",
    "        return {\"status\": \"Model not initialized\"}, 200\n",
    "    \n",
    "    with heap_lock:\n",
    "        if not data_heap:\n",
    "            return {\"status\": \"No data\"}, 200\n",
    "        _, latest_data = heapq.heappop(data_heap)\n",
    "    \n",
    "    if is_first_request:\n",
    "        # 첫 번째 요청: 행동 예측\n",
    "        obs = {\n",
    "            \"image\": np.array(latest_data[\"image\"], dtype=np.uint8),\n",
    "            \"sensors\": np.array(latest_data[\"sensors\"], dtype=np.float32)\n",
    "        }\n",
    "        with obs_lock:\n",
    "            global current_obs\n",
    "            current_obs = obs\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action, value, log_prob = model.policy(obs, deterministic=False)\n",
    "        \n",
    "        with action_lock:\n",
    "            action_idx, weight_idx = action[0]\n",
    "            weight = model.env.envs[0].weight_bins[weight_idx]\n",
    "            current_action = {\"action\": int(action_idx), \"weight\": float(weight)}\n",
    "        \n",
    "        is_first_request = False\n",
    "        return {\"status\": \"Action predicted\"}, 200\n",
    "    else:\n",
    "        # 두 번째 요청: env.step()\n",
    "        with obs_lock:\n",
    "            obs = current_obs\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action, value, log_prob = model.policy(obs, deterministic=False)\n",
    "        \n",
    "        # env.step() 호출\n",
    "        new_obs, reward, terminated, truncated, info = env.step(action[0])\n",
    "        \n",
    "        # RolloutBuffer에 저장\n",
    "        rollout_buffer.add(\n",
    "            obs=obs,\n",
    "            actions=action,\n",
    "            rewards=np.array([reward]),\n",
    "            dones=np.array([terminated]),\n",
    "            values=value,\n",
    "            log_probs=log_prob,\n",
    "            episode_starts=np.array([False])\n",
    "        )\n",
    "        step_counter += 1\n",
    "        \n",
    "        # 정책 업데이트\n",
    "        if step_counter % n_steps == 0:\n",
    "            with torch.no_grad():\n",
    "                next_value = model.policy.predict_values(new_obs)\n",
    "            rollout_buffer.compute_returns_and_advantage(last_values=next_value, dones=np.array([terminated]))\n",
    "            model.train()\n",
    "            rollout_buffer.reset()\n",
    "        \n",
    "        # 학습 종료\n",
    "        if step_counter >= total_steps:\n",
    "            model.save(\"ppo_custom_model\")\n",
    "            print(\"Learning completed\")\n",
    "            return {\"status\": \"Learning completed\"}, 200\n",
    "        \n",
    "        # 에피소드 리셋\n",
    "        if terminated or truncated:\n",
    "            obs, _ = env.reset(options={\n",
    "                \"image\": new_obs[\"image\"],\n",
    "                \"sensor_data\": new_obs[\"sensors\"].tolist()\n",
    "            })\n",
    "            with obs_lock:\n",
    "                current_obs = obs\n",
    "            is_first_request = True\n",
    "        else:\n",
    "            is_first_request = True\n",
    "        \n",
    "        return {\"status\": \"Step processed\"}, 200\n",
    "\n",
    "# 커스텀 환경\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self, simulator_url=\"http://localhost:5000\"):\n",
    "        super().__init__()\n",
    "        self.observation_space = Dict({\n",
    "            \"image\": Box(low=0, high=255, shape=(128, 128, 2), dtype=np.uint8),\n",
    "            \"sensors\": Box(low=-np.inf, high=np.inf, shape=(9,), dtype=np.float32)\n",
    "        })\n",
    "        self.action_space = MultiDiscrete([4, 10])\n",
    "        self.simulator_url = simulator_url\n",
    "        self.max_steps = 1000\n",
    "        self.step_count = 0\n",
    "        self.weight_bins = np.linspace(0.0, 0.9, 10)\n",
    "        self.render_mode = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.step_count = 0\n",
    "        if options:\n",
    "            # options로 초기 상태 설정\n",
    "            image = np.array(options[\"image\"], dtype=np.uint8)\n",
    "            sensors = np.array(options[\"sensor_data\"], dtype=np.float32)\n",
    "            return {\"image\": image, \"sensors\": sensors}, {}\n",
    "        with heap_lock:\n",
    "            heapq.heapify(data_heap)\n",
    "            if data_heap:\n",
    "                _, data = heapq.heappop(data_heap)\n",
    "            else:\n",
    "                for _ in range(4):  # 최대 1초\n",
    "                    time.sleep(0.25)\n",
    "                    with heap_lock:\n",
    "                        if data_heap:\n",
    "                            _, data = heapq.heappop(data_heap)\n",
    "                            break\n",
    "                else:\n",
    "                    raise TimeoutError(\"No initial data from simulator\")\n",
    "        image = np.array(data[\"image\"], dtype=np.uint8)\n",
    "        sensors = np.array(data[\"sensors\"], dtype=np.float32)\n",
    "        return {\"image\": image, \"sensors\": sensors}, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        global current_action\n",
    "        start_time = time.time()\n",
    "        # 두 번째 데이터 대기\n",
    "        for _ in range(2):  # 최대 0.5초\n",
    "            with heap_lock:\n",
    "                if data_heap:\n",
    "                    _, data = heapq.heappop(data_heap)\n",
    "                    print(f\"Step data at: {data['timestamp']}\")\n",
    "                    break\n",
    "            time.sleep(0.25)\n",
    "        else:\n",
    "            raise TimeoutError(\"No result data from simulator\")\n",
    "        \n",
    "        image = np.array(data[\"image\"], dtype=np.uint8)\n",
    "        sensors = np.array(data[\"sensors\"], dtype=np.float32)\n",
    "        reward = float(data[\"reward\"])\n",
    "        self.step_count += 1\n",
    "        terminated = self.step_count >= self.max_steps or data.get(\"terminated\", False)\n",
    "        truncated = False\n",
    "        info = {\"step_time\": time.time() - start_time}\n",
    "        return {\"image\": image, \"sensors\": sensors}, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"human\":\n",
    "            image = self.observation_space[\"image\"].sample()\n",
    "            cv2.imshow(\"Environment\", image[:, :, 0])\n",
    "            cv2.waitKey(1)\n",
    "        return image\n",
    "\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# 커스텀 피처 추출기\n",
    "class CustomFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            sample_image = torch.zeros(1, 2, 128, 128)\n",
    "            n_flatten = self.cnn(sample_image).shape[1]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(9, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(n_flatten + 64, features_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        image = observations[\"image\"].permute(0, 3, 1, 2).float() / 255.0\n",
    "        image_features = self.cnn(image)\n",
    "        sensor_features = self.mlp(observations[\"sensors\"])\n",
    "        combined = torch.cat([image_features, sensor_features], dim=1)\n",
    "        return self.linear(combined)\n",
    "\n",
    "# PPO 초기화\n",
    "def initialize_ppo():\n",
    "    global model, env, rollout_buffer\n",
    "    env = CustomEnv()\n",
    "    env = CustomDummyVecEnv([lambda: env])\n",
    "    rollout_buffer = DictRolloutBuffer(\n",
    "        buffer_size=n_steps,\n",
    "        observation_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        device=\"cpu\",\n",
    "        gae_lambda=0.95,\n",
    "        gamma=0.99,\n",
    "        n_envs=1,\n",
    "    )\n",
    "    model = PPO(\n",
    "        policy=MultiInputActorCriticPolicy,\n",
    "        env=env,\n",
    "        policy_kwargs={\"features_extractor_class\": CustomFeaturesExtractor},\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=n_steps,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "# Flask 서버 실행\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_ppo()\n",
    "    app.run(host=\"0.0.0.0\", port=5000, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d52678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.184069\n",
    "b = a // 0.05\n",
    "\n",
    "round(b * 0.05,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
